{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB94bOgvh0VnITZwZCOrG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/see-bear/public/blob/main/ConnectedIntelligence_2_CF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Esvg1l0GkNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1ecfcf-dc58-4d7c-9c8a-4b2d444e2cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "# cell 1 install Gradio\n",
        "!pip install gradio\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed42002-db6c-4a60-feab-6e51fd2d2532",
        "id": "RRyLfhJSIqt4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paradigm Array: [nan '224YYYY' '2242023 - Client Project Name Sample' nan nan nan nan nan\n",
            " nan nan nan 'Level 2 Matrix' 'Level 2 Category name' 'Subfolder 1'\n",
            " 'Subfolder 2' 'Subfolder 3' 'Subfolder 4' 'Subfolder 5' 'Subfolder 6'\n",
            " 'Subfolder 7' 'Subfolder 8' 'Subfolder 9' nan 'ADM' 'AGRMT' 'CHANGE'\n",
            " 'COST' 'PLAN' nan nan nan nan nan nan 'COR' 'MECH' 'ELECT' 'ELEV' 'ICAT'\n",
            " 'PM' nan nan nan nan nan 'DWG' 'ARCH' 'MECH' 'ELEC' 'ZZZZ' nan nan nan\n",
            " nan nan nan 'DSGN' 'CALC' 'MANFR' 'MTGM' 'NOTE' 'RPT' nan nan nan nan nan\n",
            " 'INSP' 'SI' 'NOC' 'CD' 'CHOR' 'ICOR' 'PRGD' 'PAMT' 'RPTS' 'SDWG' nan\n",
            " 'PUB' 'REV' 'TENDER' 'ADD' 'IFC' 'CIM' 'CIE' 'CIC' 'OM' nan\n",
            " 'Level 3 Matrix: COR Subfolders' 'Level 3 category name ' 'Subfolder 1'\n",
            " 'Subfolder 2' 'Subfolder 3' 'Subfolder 4' 'Subfolder 5' nan nan nan nan\n",
            " nan 'COR' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY' nan nan nan nan\n",
            " nan 'MECH' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY' nan nan nan\n",
            " nan nan 'ELECT' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY' nan nan\n",
            " nan nan nan 'ELEV' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY' nan\n",
            " nan nan nan nan 'ICAT' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY'\n",
            " nan nan nan nan nan 'PM' 'OWNER' 'DESTM' 'CONTRCTR' 'SUBCONTR' 'AUTHRTY'\n",
            " nan nan nan nan nan 'ZZZZ' 'date format xxxx/yy/zz-(file source)' nan nan\n",
            " nan nan nan nan nan nan 'Level 4 Matrix' 'Level 4 category name'\n",
            " 'ADM Subfolder' 'COR Subfolder Example' 'DWG Subfolder Example' nan nan\n",
            " nan nan nan nan nan 'AGRMT' 'OWNER,  '\n",
            " 'Additional project-specific folders' 'DWG ' nan nan nan nan nan nan nan\n",
            " nan 'DESTM,' 'any' 'Revit' nan nan nan nan nan nan nan nan 'CONTRCTR'\n",
            " 'any' 'Revceived' nan nan nan nan nan nan]\n"
          ]
        }
      ],
      "source": [
        "#Cell 2 load paradigm array\n",
        "# @title Default title text\n",
        "# Load the paradigm array from the uploaded Excel file\n",
        "paradigm_file_path =  '/content/Class_A_array3.xlsx'\n",
        "paradigm_df = pd.read_excel(paradigm_file_path)\n",
        "paradigm_array = paradigm_df.values.flatten()  # Convert to a flat array\n",
        "print(\"Paradigm Array:\", paradigm_array)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 investigate folder structure\n",
        "import os\n",
        "\n",
        "def investigate_folder_structure(path='content/224_Sample.zip'):\n",
        "    folder_structure = []\n",
        "    # Initialize root and level outside the loop to store their final values\n",
        "    root = ''\n",
        "    level = 0\n",
        "\n",
        "    for root, dirs, _ in os.walk(path):  # Assign root and level in the loop\n",
        "        for dir_name in dirs:\n",
        "            level = root.replace(path, '').count(os.sep) # use path instead of root_path\n",
        "            folder_structure.append((f\"L{level}\", dir_name))\n",
        "\n",
        "    # Now root and level will have the last values from the loop\n",
        "    return folder_structure, root, level # Return root and level\n",
        "\n",
        "# Call the function and assign the returned values to variables\n",
        "folder_structure, root_val, level_val = investigate_folder_structure()\n",
        "print(f\"Root: {root_val}, Level: {level_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1niAQJNOe06",
        "outputId": "026052e1-6b21-4a05-a3c2-e5d45742e41d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root: , Level: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 4 setup temp directory\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import gradio as gr\n",
        "\n",
        "def compare_folder_structures(zip_file):\n",
        "    # Define a temporary directory to extract the zip file\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        # Create the temporary directory\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        # Try to open and extract the zip file\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "                z.extractall(temp_dir)\n",
        "        except zipfile.BadZipFile:\n",
        "            return \"Error: The uploaded file is not a valid zip file.\", [], []\n",
        "\n",
        "        # Investigate the folder structure with full paths\n",
        "        folder_structure = []\n",
        "        for root, dirs, _ in os.walk(temp_dir):\n",
        "            for dir_name in dirs:\n",
        "                # Use os.path.relpath for determining level\n",
        "                level = os.path.relpath(root, temp_dir).count(os.sep)\n",
        "                full_path = os.path.join(root, dir_name)\n",
        "                folder_structure.append((f\"L{level}\", full_path))\n",
        "\n",
        "        # Compare with the paradigm array (ensuring it contains only folder names)\n",
        "        folder_structure_set = {os.path.basename(name) for _, name in folder_structure}\n",
        "        missing_folders = [name for name in paradigm_array if name not in folder_structure_set]\n",
        "\n",
        "        # Create the result table and missing folders table\n",
        "        result = \"Standards Compliant\" if not missing_folders else \"Lacks the following folders\"\n",
        "        result_table = [{\"Level\": level, \"Name\": os.path.basename(name), \"Full Path\": name} for level, name in folder_structure]\n",
        "        missing_table = [{\"Missing Folder\": name} for name in missing_folders]\n",
        "\n",
        "    except Exception as e:\n",
        "        # Generic error handling for unexpected issues\n",
        "        return f\"Error: An unexpected issue occurred - {str(e)}\", [], []\n",
        "    finally:\n",
        "        # Ensure temporary directory is cleaned up\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "    return result, result_table, missing_table, paradigm_array, \"Debug logs: All steps completed successfully.\"\n"
      ],
      "metadata": {
        "id": "-PJ_ZGyvRMyT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 5 function to handle comparison of file structures\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Example paradigm array (replace this with actual data from your Excel file)\n",
        "paradigm_array = [\"Folder1\", \"Folder2\", \"Folder3/Subfolder\"]\n",
        "\n",
        "# Function to handle file structure comparison\n",
        "def handle_user_actions(zip_file):\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        # Step 1: Validate the uploaded file\n",
        "        if not zip_file.name.endswith(\".zip\"):\n",
        "            return \"Error: Uploaded file is not a .zip archive.\", [], [], \"Invalid input. Please upload a valid .zip file.\"\n",
        "\n",
        "        # Step 2: Extract the zip file into a temporary directory\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "                z.extractall(temp_dir)\n",
        "        except zipfile.BadZipFile:\n",
        "            return \"Error: Uploaded file is not a valid zip file.\", [], [], \"Upload a valid .zip file.\"\n",
        "\n",
        "        # Step 3: Investigate folder structure\n",
        "        folder_structure = []\n",
        "        for root, dirs, _ in os.walk(temp_dir):\n",
        "            for dir_name in dirs:\n",
        "                level = os.path.relpath(root, temp_dir).count(os.sep)\n",
        "                folder_structure.append((f\"L{level}\", os.path.join(root, dir_name)))\n",
        "\n",
        "        # Step 4: Validate data and compare with the paradigm array\n",
        "        folder_names_set = {os.path.basename(name) for _, name in folder_structure}\n",
        "        missing_folders = [folder for folder in paradigm_array if folder not in folder_names_set]\n",
        "\n",
        "        # Step 5: Prepare outputs\n",
        "        result = \"Standards Compliant\" if not missing_folders else \"Lacks the following folders\"\n",
        "        result_table = [{\"Level\": level, \"Name\": os.path.basename(name)} for level, name in folder_structure]\n",
        "        missing_table = [{\"Missing Folder\": folder} for folder in missing_folders]\n",
        "\n",
        "        # Return results\n",
        "        return result, result_table, missing_table, \"Check missing folders and click 'Proceed' or 'Cancel'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Generic error handling\n",
        "        return f\"Error: {str(e)}\", [], [], \"An unexpected error occurred.\"\n",
        "\n",
        "    finally:\n",
        "        # Step 6: Ensure temp_dir cleanup\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "# Function to create missing folders based on user selection\n",
        "def create_missing_folders(zip_file, selected_folders):\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        # Extract the zip file again\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "            z.extractall(temp_dir)\n",
        "\n",
        "        # Create missing folders\n",
        "        created = []\n",
        "        for folder in selected_folders:\n",
        "            full_path = os.path.join(temp_dir, folder)\n",
        "            os.makedirs(full_path, exist_ok=True)\n",
        "            created.append(folder)\n",
        "\n",
        "        return f\"Successfully created folders: {', '.join(created)}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "    finally:\n",
        "        # Cleanup temp_dir\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n"
      ],
      "metadata": {
        "id": "fuG_IyckhVGt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 6 handle user actions\n",
        "import gradio as gr\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Example paradigm array (replace this with actual data from your Excel file)\n",
        "paradigm_array = [\"Folder1\", \"Folder2\", \"Folder3/Subfolder\"]\n",
        "print(\"Paradigm Array:\", paradigm_array)\n",
        "\n",
        "# Function to handle file structure comparison\n",
        "def handle_user_actions(zip_file):\n",
        "    print(f\"Uploaded file name: {zip_file.name}\")  # Debugging line\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        print(\"Starting to process uploaded file...\")\n",
        "        print(\"Step 1: Starting file validation...\")\n",
        "        # Step 1: Validate the uploaded file\n",
        "        if not zip_file.name.endswith(\".zip\"):\n",
        "            print(\"Error: Uploaded file is not a zip file.\")\n",
        "            return \"Error: Uploaded file is not a .zip archive.\", [], [], \"Invalid input. Please upload a valid .zip file.\"\n",
        "        print(\"Step 1: File validation complete.\")\n",
        "        print(\"Step 2: Extracting file...\")\n",
        "\n",
        "        # Step 2: Extract the zip file into a temporary directory\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "                print(\"Extracting files...\")\n",
        "                z.extractall(temp_dir)\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"Error during extraction: {e}\")\n",
        "            return \"Error: Uploaded file is not a valid zip file.\", [], [], \"Upload a valid .zip file.\"\n",
        "        print(\"Step 2: File extraction complete.\")\n",
        "\n",
        "        print(\"Step 3: Investigating folder structure...\")\n",
        "        # Step 3: Investigate folder structure\n",
        "        print(\"Investigating folder structure...\")\n",
        "        folder_structure = []\n",
        "        for root, dirs, _ in os.walk(temp_dir):\n",
        "            for dir_name in dirs:\n",
        "                level = os.path.relpath(root, temp_dir).count(os.sep)\n",
        "                folder_structure.append((f\"L{level}\", os.path.join(root, dir_name)))\n",
        "                print(f\"Level {level}: {dir_name}\")\n",
        "\n",
        "        print(\"Step 4: Comparing folder structure...\")\n",
        "        # Step 4: Validate data and compare with the paradigm array\n",
        "        print(\"Comparing with paradigm array...\")\n",
        "        folder_names_set = {os.path.basename(name) for _, name in folder_structure}\n",
        "        missing_folders = [folder for folder in paradigm_array if folder not in folder_names_set]\n",
        "        print(\"Step 4: Comparison complete.\")\n",
        "        print(f\"Missing Folders: {missing_folders}\")\n",
        "\n",
        "        print(\"Step 5: Preparing outputs...\")\n",
        "        # Step 5: Prepare outputs\n",
        "        result = \"Standards Compliant\" if not missing_folders else \"Lacks the following folders\"\n",
        "        result_table = [{\"Level\": level, \"Name\": os.path.basename(name)} for level, name in folder_structure]\n",
        "        missing_table = [{\"Missing Folder\": folder} for folder in missing_folders]\n",
        "\n",
        "        # Return results\n",
        "        return result, result_table, missing_table, \"Check missing folders and click 'Proceed' or 'Cancel'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unhandled exception: {e}\")\n",
        "        # Generic error handling\n",
        "        return f\"Error: {str(e)}\", [], [], \"An unexpected error occurred.\"\n",
        "\n",
        "    finally:\n",
        "        # Step 6: Ensure temp_dir cleanup\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "# Function to create missing folders based on user selection\n",
        "def create_missing_folders(zip_file, selected_folders):\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        # Extract the zip file again\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "            z.extractall(temp_dir)\n",
        "\n",
        "        # Create missing folders\n",
        "        created = []\n",
        "        for folder in selected_folders:\n",
        "            full_path = os.path.join(temp_dir, folder)\n",
        "            os.makedirs(full_path, exist_ok=True)\n",
        "            created.append(folder)\n",
        "\n",
        "        return f\"Successfully created folders: {', '.join(created)}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "        print(f\"Error encountered: {e}\")\n",
        "        raise  # Re-raise to let Gradio display the error\n",
        "    finally:\n",
        "        # Cleanup temp_dir\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=handle_user_actions,\n",
        "    inputs=gr.File(label=\"Upload folder structure as .zip\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Compliance Result\"),\n",
        "        gr.Dataframe(label=\"Folder Structure\"),\n",
        "        gr.Dataframe(label=\"Missing Folders\"),\n",
        "        gr.Textbox(label=\"Instructions\"),\n",
        "        gr.Textbox(label=\"Standard Folder Structure\"),\n",
        "        gr.Textbox(label=\"Debug Logs\"),  # Add a new field for logs\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "YuDHs8JkvM3I",
        "outputId": "3a18b53e-a2d0-45e5-feb4-e8e6373b2e2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paradigm Array: ['Folder1', 'Folder2', 'Folder3/Subfolder']\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2e3b36b575de836bd2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2e3b36b575de836bd2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 7 -\n",
        "import logging\n",
        "import gradio as gr\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Display the paradigm array as the \"Standard Folder Structure\"\n",
        "def standard_folder_view():\n",
        "    return paradigm_array.tolist()\n",
        "\n",
        "# Compare folder structures and handle user input\n",
        "def handle_user_actions_with_standard(zip_file):\n",
        "    result, result_table, missing_table = compare_folder_structures(zip_file)\n",
        "\n",
        "    # If the folder structure is compliant\n",
        "    if result == \"Standards Compliant\":\n",
        "        return (\n",
        "            result,\n",
        "            result_table,\n",
        "            None,\n",
        "            paradigm_array.tolist(),\n",
        "            \"Folder structure matches the standard.\",\n",
        "        )\n",
        "\n",
        "    # For non-compliant structures, show missing folders and instructions\n",
        "    missing_folders_checkboxes = [\n",
        "        {\"Label\": folder[\"Missing Folder\"], \"Value\": False} for folder in missing_table\n",
        "    ]\n",
        "\n",
        "    return (\n",
        "        result,\n",
        "        result_table,\n",
        "        missing_folders_checkboxes,\n",
        "        paradigm_array.tolist(),\n",
        "        \"Check the boxes for missing folders to add, then click 'Proceed' or 'Cancel'.\",\n",
        "    )\n",
        "\n",
        "# Folder creation logic based on user input\n",
        "def create_missing_folders(zip_file, selected_folders):\n",
        "    temp_dir = \"temp_dir\"\n",
        "    try:\n",
        "        # Re-extract zip file to a temporary directory\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file.name, 'r') as z:\n",
        "            z.extractall(temp_dir)\n",
        "\n",
        "        # Create missing folders\n",
        "        created_folders = []\n",
        "        for folder in selected_folders:\n",
        "            if folder[\"Value\"]:  # If checkbox is checked\n",
        "                full_path = os.path.join(temp_dir, folder[\"Label\"])\n",
        "                os.makedirs(full_path, exist_ok=True)\n",
        "                created_folders.append(full_path)\n",
        "\n",
        "        return f\"Created missing folders: {', '.join(created_folders)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "    finally:\n",
        "        # Clean up temporary directory\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "# Add buttons for interactivity\n",
        "def action_buttons(selected_folders):\n",
        "    return f\"Selected actions: {', '.join([folder['Label'] for folder in selected_folders if folder['Value']])}\"\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=handle_user_actions_with_standard,\n",
        "    inputs=gr.File(label=\"Upload folder structure as .zip\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Compliance Result\"),\n",
        "        gr.Dataframe(label=\"Folder Structure\"),\n",
        "        gr.CheckboxGroup(label=\"Missing Folders to Add\"),\n",
        "        gr.Dataframe(label=\"Standard Folder Structure\"),\n",
        "        gr.Textbox(label=\"Instructions\"),\n",
        "    ],\n",
        "    live=True,\n",
        ")\n",
        "\n",
        "# Log the launch of the interface\n",
        "logging.info(\"Launching Gradio interface...\")\n",
        "\n",
        "# Proceed and Cancel Button Actions\n",
        "def proceed_action(zip_file, selected_folders):\n",
        "    return create_missing_folders(zip_file, selected_folders)\n",
        "\n",
        "def cancel_action():\n",
        "    return \"Operation canceled. No changes were made.\"\n",
        "\n",
        "# Launch the Interface\n",
        "try:\n",
        "    interface.launch(share=True)\n",
        "    logging.info(\"Gradio interface launched successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error while launching Gradio interface: {e}\")\n",
        "\n",
        "print(\"Debugging test: Is this visible?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "0kRW5zIK2D0i",
        "outputId": "0f94057d-a300-4540-e380-694adbe7a7a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c92e9a9f42ffe88dca.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c92e9a9f42ffe88dca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debugging test: Is this visible?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#interface.launch(debug=True, share=true)"
      ],
      "metadata": {
        "id": "cpDPJcdnYJfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing output visibility in Colab.\")"
      ],
      "metadata": {
        "id": "bjR3xYx5XjU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}